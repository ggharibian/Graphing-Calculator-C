{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "Linda_Bessin_KNN_Algo.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "0PeS3bubycdO",
        "WF5SpRzGyml0",
        "UBJE5-Djy4cn"
      ],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ggharibian/Graphing-Calculator-C/blob/main/Linda_Bessin_KNN_Algo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0PeS3bubycdO"
      },
      "source": [
        "# Setup\n",
        "*90 lines*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MbTl2D6NbiZ"
      },
      "source": [
        "# Run this cell to set up the notebook\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "from datascience import *\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "drive.mount('/content/drive', timeout_ms=9999999999999999999999999999999999999999999999999999999999999999999999999999)\n",
        "\n",
        "# These lines set up the plotting functionality and formatting.\n",
        "import matplotlib\n",
        "matplotlib.use('Agg', warn=False)\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plots\n",
        "plots.style.use('fivethirtyeight')\n",
        "import warnings\n",
        "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
        "\n",
        "#Bessin-specific functions\n",
        "def table_setup(t_name,):\n",
        "    def tt2(s):\n",
        "        return s[:-2]\n",
        "        \n",
        "    t = pd.read_csv('/content/drive/My Drive/Notebooks/Bessin/Data/' + t_name + '.csv')\n",
        "    if 'PrecinctName' in t.columns:\n",
        "        t['PrecinctName'] = t['PrecinctName'].apply(tt2)\n",
        "    elif 'PrecinctName ' in t.columns:\n",
        "        t['PrecinctName '] = t['PrecinctName '].apply(tt2)\n",
        "    return t.rename({'Voter File VANID': 'VANID', 'FirstName': 'firstname', 'MiddleName': 'middlename', 'LastName': 'lastname', 'Suffix': 'suffix', 'Sex': 'sex', 'Age': 'age', 'Age ': 'age', 'mAddress': 'mailingaddress', 'mCity': 'city', 'mState': 'state', 'mZip5': 'zip', 'mZip4': 'zip_ext', 'PreferredEmail': 'preferredemail', 'Preferred Phone': 'preferred Phone', 'PrecinctName': 'precinct', 'RaceName': 'race', 'Party': 'party', 'Party ': 'party', '2016:CmpgnFnc': 'campaignfinancing', '2016:ClgFndng': 'collegefunding', '2016:GvPrvcy': 'govtprivacy', '2016:PdLv': 'paidleave', '2016:NonChrst': 'nochristian', '2016:OthChrst': 'otherchristian', '2016:TSM:TeaPa': 'teaparty', 'Autho': 'authoritarian', 'Comp': 'compassion', 'EcoPop': 'econpopulism', 'Env': 'environment', 'FrTrd': 'freetrade', 'Glbl': 'globalism', 'Guns': 'guns', 'HC': 'healthcare', 'HCWmn': 'healthcarewomen', 'Imm': 'immigration', 'Mili': 'military', 'Poor': 'poor', 'Popu': 'populism', 'Pres': 'presidential', 'RacRes': 'racialresentment', 'Reg': 'regulation', 'RelFrdm': 'religiousfreedom', 'Tax': 'tax', 'Trad': 'traditionalism', 'InstTrst': 'institutiontrust', 'ClmChng': 'climatechange', 'CollGrd': 'collegegrad', 'HSOnly': 'hsonly', 'Ideo': 'ideology', 'LocVo': 'localvoter', 'PthCit': 'pathtocitizen', 'PrChc': 'prochoice', 'ProgTax': 'progressivetax', 'WorCl': 'workingclass', 'Cosmo': 'cosmopolitanism', 'CrimJustRef': 'criminaljusticereform', 'Diplomacy': 'diplomacy', 'EthNat': 'ethnonationalism', 'IncInequ': 'incomeinequality', 'Infrastruct': 'infrastructure', 'TSMAct': 'activist', 'CanLeg': 'cannabislegalization', '2016:ChldPrsnt': 'childrenpresent', 'TSMGnCntrl': 'guncontrol', 'TSMGun': 'gunowner', 'TSM_Ideo_Enh': 'ideologyenhanced', '2016:IncRnk': 'incomerank', 'UnionSupport': 'unionsupport', '2016:Mrrg': 'marriage', 'MarEqu': 'marriageequality', 'MidGenTO': 'midtermturnout', 'MidGenTOEnth': 'midtermenthusiasm', '2016:MnWg': 'minimumwage', 'NonPresPriTO': 'nonprespriturnout', 'OffGenTO': 'offgeneralturnout', 'TSM:Part': 'partisan', 'PresGenTO': 'presgeneralturnout', 'PresPriTO': 'prespriturnout', '2016:Cath': 'catholic', '2016:Evang': 'evangelical', 'Jewish': 'jewish', 'Mormon': 'mormon', 'NonRelig': 'nonreligious', 'TSMTrumpResist': 'trumpresistance', 'TSMTrumpSup': 'trumpsupport', 'TSMVet': 'veteran', 'Urb ': 'urbanicity'}, axis='columns')\n",
        "\n",
        "def precinct_breakdown(t, bkdn, pnt=None, in_percent=False):\n",
        "    p = pd.DataFrame()\n",
        "    if 'precinct' in t.columns:\n",
        "        t = t[t['precinct'] == pnt]\n",
        "        p['precinct'] = [pnt]\n",
        "    for k in list(bkdn):\n",
        "        if k in t.columns:\n",
        "            for d in bkdn[k]:\n",
        "                if d in list(t[k].unique()):\n",
        "                    ct = t.groupby(k)['LastName'].count()[d]\n",
        "                else:\n",
        "                    ct = 0\n",
        "                if in_percent == True and type(pnt) == str:\n",
        "                    ct = ct / len(t[t['precinct'] == pnt].index)\n",
        "                elif in_percent == True and not type(pnt) == str:\n",
        "                    ct = ct / len(t.index)\n",
        "                p[d] = [ct]\n",
        "    return p\n",
        "\n",
        "def mult_breakdown(tbl, bkdn, pr_list=[], in_percent=False):\n",
        "    if pr_list == []:\n",
        "        pr_list = list(tbl['precinct'].unique())\n",
        "    df1 = pd.DataFrame()\n",
        "    for i in pr_list:\n",
        "        df1 = df1.append(precinct_breakdown(tbl, bkdn, i, in_percent), ignore_index=True)\n",
        "    return df1\n",
        "\n",
        "def zip_p1_full(t, dict): # NEEDS TO BE TRANSFORMED INTO PANDAS\n",
        "    tbl = zip_precincts(t, list(dict)[0], dict[list(dict)[0]]).sort('precinct')\n",
        "    for k in list(dict)[1:]:\n",
        "        tbl = tbl.join('precinct', zip_precincts(t, k, dict[k]))\n",
        "    return tbl\n",
        "\n",
        "def save_file(t, name, idx=False):\n",
        "    t.to_excel(\"/content/drive/My Drive/Notebooks/Bessin/Sheets/\" + name + \".xlsx\", index=idx, header=True)\n",
        "    print('Saved as \"' + name + '\"')\n",
        "    return None\n",
        "\n",
        "breakdowns = {'sex': ['M', 'F', 'U'],\n",
        "              'age': [(18, 25), (26, 49), (50, 65), (66, 80), (81, 100), (101, 300)],\n",
        "              'party': ['D', 'R', 'U', 'G', 'L', 'P', 'O'],\n",
        "              'race': ['Asian', 'Caucasian', 'Hispanic', 'Native American', 'Uncoded']}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQwWJDMKNbif"
      },
      "source": [
        "#import and setup data; enter file name, must be csv in Data folder\n",
        "BVoters = table_setup('BVotersFull')\n",
        "num_of_voters_full = 66873\n",
        "linda_VANID = 7766030\n",
        "kons_VANID = 15702787\n",
        "tam_VANID = 7929336\n",
        "schultz_VANID = 47146692\n",
        "mano_VANID = 46376079\n",
        "murphy_VANID = 7842797\n",
        "machine_data_points = ['partisan', 'compassion', 'climatechange', 'tax', 'localvoter', 'progressivetax', 'incomeinequality', 'infrastructure', 'incomerank', 'minimumwage', 'midtermturnout', 'nonprespriturnout', 'trumpresistance']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QY3FucOwcOn"
      },
      "source": [
        "machine_data = BVoters[['VANID', 'lastname', 'firstname', 'sex', 'age', 'party', 'partisan', 'mailingaddress', 'city', 'state', 'zip', 'preferredemail', 'preferred Phone', 'precinct', 'authoritarian', 'compassion', 'climatechange', 'racialresentment', 'tax', 'localvoter', 'progressivetax', 'incomeinequality', 'infrastructure', 'incomerank', 'minimumwage', 'midtermturnout', 'nonprespriturnout', 'trumpresistance', 'trumpsupport']]\n",
        "machine_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T85wPG7dAPNK"
      },
      "source": [
        "linda = machine_data[machine_data['VANID'] == linda_VANID].iloc[0]\n",
        "kons = machine_data[machine_data['VANID'] == kons_VANID].iloc[0]\n",
        "tam = machine_data[machine_data['VANID'] == tam_VANID].iloc[0]\n",
        "schultz = machine_data[machine_data['VANID'] == schultz_VANID].iloc[0]\n",
        "mano = machine_data[machine_data['VANID'] == mano_VANID].iloc[0]\n",
        "murphy = machine_data[machine_data['VANID'] == murphy_VANID].iloc[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WF5SpRzGyml0"
      },
      "source": [
        "# linda_score functions\n",
        "*36 lines*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUpLC_v6ah7N"
      },
      "source": [
        "def linda_score(VANID):\n",
        "    #requires existence of machine_data, which is derived from BVotersFull\n",
        "    row = machine_data[machine_data['VANID'] == VANID].iloc[0]\n",
        "    # row_series = machine_data[machine_data['VANID'] == VANID].iloc[0]\n",
        "    if row['party'] in ['R', 'L', 'G', 'O', 'P']:\n",
        "        if score_accuracy(VANID) == 0:\n",
        "            return 0\n",
        "        if row['partisan'] >= 50:\n",
        "            return 0\n",
        "        return 100 - linda_distance(VANID)\n",
        "    if row['party'] == 'D':\n",
        "        if score_accuracy(VANID) == 0:\n",
        "            return 100\n",
        "        if row['partisan'] >= 50:\n",
        "            return 100 - (linda_distance(VANID) * .5)\n",
        "        return 100 - linda_distance(VANID)\n",
        "    if row['party'] == 'U':\n",
        "        if score_accuracy(VANID) == 0:\n",
        "            return 50\n",
        "        if row['partisan'] >= 50:\n",
        "            return 100 - (linda_distance(VANID) * 1.5)\n",
        "        return 100 - linda_distance(VANID)\n",
        "\n",
        "def linda_score_report(VANID):\n",
        "    print('Linda Score: ' + str(linda_score(VANID)) + '\\nLinda Score Accuracy: ' + str(score_accuracy(VANID)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHKr8Kue_MZK"
      },
      "source": [
        "def score_accuracy(VANID):\n",
        "    #requires existence of machine_data, which is derived from BVotersFull\n",
        "    row = machine_data[machine_data['VANID'] == VANID].iloc[0]\n",
        "    row_spaces_filled = 0\n",
        "    for i in machine_data_points:\n",
        "        row_space_filled = row[i] == row[i]\n",
        "        if row_space_filled:\n",
        "            row_spaces_filled += 1\n",
        "    return row_spaces_filled / len(machine_data_points)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSLgN1P7DN6J"
      },
      "source": [
        "linda_score_report(vanid_finder('Weinberg', 'Diana'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQ9dU423EMZH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBJE5-Djy4cn"
      },
      "source": [
        "# Classify functions\n",
        "*60 lines*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7ET0DIn92Oi"
      },
      "source": [
        "def row_to_mdp_array(row):\n",
        "    if type(row) == pd.core.series.Series:\n",
        "        return make_array(row[machine_data_points])\n",
        "    return make_array(row[machine_data_points].iloc[0])\n",
        "\n",
        "def row_to_array(row):\n",
        "    if type(row) == pd.core.series.Series:\n",
        "        return make_array(row)\n",
        "    return make_array(row.iloc[0])\n",
        "\n",
        "def iloc_row_to_df(row):\n",
        "    return pd.DataFrame(row, index=machine_data.columns).transpose()\n",
        "\n",
        "def distance(array1, array2):\n",
        "    row_distance = 0\n",
        "    for i in range(len(array1)):\n",
        "        row_distance += (array1.item(i) - array2.item(i)) ** 2\n",
        "    return row_distance ** .5\n",
        "\n",
        "def vanid_finder(last, first):\n",
        "    return machine_data[machine_data['lastname'] == last][machine_data['firstname'] == first].iloc[0]['VANID']\n",
        "\n",
        "def classify(VANID, train=iloc_row_to_df(linda).append(iloc_row_to_df(kons)).append(iloc_row_to_df(tam)).append(iloc_row_to_df(murphy))):\n",
        "    row = machine_data[machine_data['VANID'] == VANID].iloc[0]\n",
        "    test_row_features_array = row_to_mdp_array(row)\n",
        "    distances = make_array()\n",
        "    for i in range(4):\n",
        "        train_row_features_array = row_to_mdp_array(train.iloc[i])\n",
        "        distances = np.append(distances, distance(train_row_features_array, test_row_features_array))\n",
        "    train['distance'] = distances\n",
        "    nearest_neighbors = train.sort_values('distance')\n",
        "    closest_label = nearest_neighbors.iloc[0]['firstname'] + ' ' + nearest_neighbors.iloc[0]['lastname']\n",
        "    # print('Score Accuracy: ' + str(score_accuracy(VANID)))\n",
        "    return closest_label\n",
        "\n",
        "def distance_comps(VANID):\n",
        "    row = machine_data[machine_data['VANID'] == VANID].iloc[0]\n",
        "    test_row_features_array = row_to_mdp_array(row)\n",
        "    distances = make_array()\n",
        "    for i in range(4):\n",
        "        train_row_features_array = row_to_mdp_array(train.iloc[i])\n",
        "        distances = np.append(distances, distance(train_row_features_array, test_row_features_array))\n",
        "    train['distance'] = distances\n",
        "    return train[['firstname', 'lastname', 'distance']].sort_values('distance')\n",
        "\n",
        "def linda_distance(VANID, train=iloc_row_to_df(linda).append(iloc_row_to_df(kons)).append(iloc_row_to_df(tam)).append(iloc_row_to_df(murphy))):\n",
        "    row = machine_data[machine_data['VANID'] == VANID].iloc[0]\n",
        "    test_row_features_array = row_to_mdp_array(row)\n",
        "    distances = make_array()\n",
        "    for i in range(4):\n",
        "        train_row_features_array = row_to_mdp_array(train.iloc[i])\n",
        "        distances = np.append(distances, distance(train_row_features_array, test_row_features_array))\n",
        "    train['distance'] = distances\n",
        "    # print('Score Accuracy: ' + str(score_accuracy(VANID)))\n",
        "    return train.iloc[0]['distance']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5Z--hO2RQCc"
      },
      "source": [
        "classify(vanid_finder('Kahn', 'Louie'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIlQ3EhzK4ZH"
      },
      "source": [
        "train = iloc_row_to_df(linda).append(iloc_row_to_df(kons)).append(iloc_row_to_df(tam)).append(iloc_row_to_df(murphy))\n",
        "train[machine_data_points]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGt0B9N7CDj6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTMD3fQ0GmZt"
      },
      "source": [
        "# Application to Machine Data\n",
        "\n",
        "*The Ultimate Data Machine*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POkyrNeWGyKO"
      },
      "source": [
        "def ultimate_data_machine(df=machine_data, columns=['VANID', 'lastname', 'firstname', 'sex', 'age', 'party', 'mailingaddress', 'city', 'state', 'zip', 'preferredemail', 'preferred Phone', 'precinct', 'linda_score', 'closest_dem_candidate', 'score_accuracy']):\n",
        "    score_array = make_array()\n",
        "    acc_array = make_array()\n",
        "    exp_cand_array = make_array()\n",
        "    for vanid in list(df['VANID']):\n",
        "        score_array = np.append(score_array, linda_score(vanid))\n",
        "        exp_cand_array = np.append(exp_cand_array, classify(vanid))\n",
        "        acc_array = np.append(acc_array, score_accuracy(vanid))\n",
        "    df['linda_score'] = score_array\n",
        "    df['closest_dem_candidate'] = exp_cand_array\n",
        "    df['score_accuracy'] = acc_array\n",
        "    return df[columns]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2JqW0jaG0tC"
      },
      "source": [
        "ultimate_data_machine(machine_data.take(range(50))) #IT WORKS!!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQbTsRrCIfIJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}